{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc82a868",
   "metadata": {},
   "source": [
    "# üß† Convolutional Neural Networks (CNNs)\n",
    "\n",
    "As **Redes Neurais Convolucionais (CNNs)** s√£o uma arquitetura de rede neural projetada para processar dados com uma estrutura de grade, como imagens. Elas s√£o amplamente utilizadas em **vis√£o computacional**, **processamento de v√≠deo**, **reconhecimento de padr√µes** e at√© mesmo em **processamento de linguagem natural**.\n",
    "\n",
    "---\n",
    "\n",
    "## üì∑ O que √© uma CNN?\n",
    "\n",
    "Uma **CNN** √© composta por camadas especializadas que podem extrair **caracter√≠sticas espaciais** e **hier√°rquicas** dos dados de entrada. Ao contr√°rio das redes totalmente conectadas (Fully Connected), elas utilizam opera√ß√µes matem√°ticas chamadas **convolu√ß√µes** para capturar rela√ß√µes locais.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ† Estrutura de uma CNN\n",
    "\n",
    "Uma CNN √© composta principalmente por 3 tipos de camadas:\n",
    "\n",
    "### 1Ô∏è‚É£ **Camada Convolucional**\n",
    "- Aplica **filtros (kernels)** sobre a entrada para extrair **features** como bordas, texturas e padr√µes.\n",
    "- F√≥rmula da opera√ß√£o de convolu√ß√£o:\n",
    "  \\[\n",
    "  (I * K)(x, y) = \\sum_{m}\\sum_{n} I(m, n) \\cdot K(x-m, y-n)\n",
    "  \\]\n",
    "  Onde:\n",
    "  - \\(I\\): imagem de entrada\n",
    "  - \\(K\\): kernel/filtro\n",
    "  - \\(*\\): opera√ß√£o de convolu√ß√£o\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ **Camada de Pooling**\n",
    "- Reduz a **dimensionalidade** das features, mantendo as informa√ß√µes mais relevantes.\n",
    "- Tipos comuns:\n",
    "  - **Max Pooling**: seleciona o valor m√°ximo em cada regi√£o.\n",
    "  - **Average Pooling**: calcula a m√©dia dos valores em cada regi√£o.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ **Camadas Completamente Conectadas (Fully Connected)**\n",
    "- Conectam todos os neur√¥nios para realizar a **classifica√ß√£o final**.\n",
    "\n",
    "---\n",
    "\n",
    "## üé® Fluxo de uma CNN\n",
    "\n",
    "1. **Entrada**: imagem ou dado com estrutura de grade.\n",
    "2. **Convolu√ß√µes**: aplica√ß√£o de filtros para extrair features.\n",
    "3. **Pooling**: redu√ß√£o da dimensionalidade.\n",
    "4. **Flattening**: transforma√ß√£o das features em vetor.\n",
    "5. **Camadas Densas**: processam o vetor para gerar a sa√≠da.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Aplica√ß√µes de CNNs\n",
    "\n",
    "‚úÖ **Classifica√ß√£o de Imagens** (ex.: gatos vs. cachorros)  \n",
    "‚úÖ **Detec√ß√£o de Objetos** (ex.: YOLO, SSD)  \n",
    "‚úÖ **Segmenta√ß√£o de Imagens** (ex.: U-Net)  \n",
    "‚úÖ **Reconhecimento Facial**  \n",
    "‚úÖ **An√°lise de V√≠deo**  \n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Vantagens das CNNs\n",
    "\n",
    "‚úî Reduzem o n√∫mero de par√¢metros com compartilhamento de pesos.  \n",
    "‚úî Capturam **rela√ß√µes espaciais** entre pixels.  \n",
    "‚úî Escalam bem para dados de alta dimens√£o.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìö Exemplos Populares de Arquiteturas CNN\n",
    "\n",
    "- **LeNet-5**: pioneira para reconhecimento de d√≠gitos escritos √† m√£o.  \n",
    "- **AlexNet**: revolucionou o ImageNet em 2012.  \n",
    "- **VGGNet**: usa filtros 3x3 para profundidade.  \n",
    "- **ResNet**: introduziu conex√µes residuais (skip connections).\n",
    "\n",
    "---\n",
    "\n",
    "## üî• F√≥rmula da Convolu√ß√£o Visualizada\n",
    "\n",
    "\n",
    "üì• **Imagem (Entrada)**  \n",
    "‚û° Aplica√ß√£o de **filtros (kernels)**  \n",
    "‚û° üì§ **Mapa de caracter√≠sticas (Feature Map)**\n",
    "\n",
    "---\n",
    "\n",
    "> üìù **Resumo**: CNNs s√£o uma ferramenta poderosa para tarefas que exigem entender dados espaciais e visuais. Elas s√£o a espinha dorsal de muitas aplica√ß√µes modernas de intelig√™ncia artificial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7dd0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f741c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c857101",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906b61f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294df75a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0af71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6092aa2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f0b1ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f73f1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a207e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53e3a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d65caf6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b2419",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35b470",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4422a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
